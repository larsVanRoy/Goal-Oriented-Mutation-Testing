@misc{ahamed2010studying,
      title={Studying the Feasibility and Importance of Software Testing: An Analysis}, 
      author={S. S. Riaz Ahamed},
      year={2010},
      eprint={1001.4193},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@inproceedings{10.1145/1572272.1572282,
	author = {Schuler, David and Dallmeier, Valentin and Zeller, Andreas},
	title = {Efficient Mutation Testing by Checking Invariant Violations},
	year = {2009},
	isbn = {9781605583389},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1572272.1572282},
	doi = {10.1145/1572272.1572282},
	abstract = {Mutation testing measures the adequacy of a test suite by seeding artificial defects (mutations) into a program. If a mutation is not detected by the test suite, this usually means that the test suite is not adequate. However, it may also be that the mutant keeps the program's semantics unchanged-and thus cannot be detected by any test. Such equivalent mutants have to be eliminated manually, which is tedious.We assess the impact of mutations by checking dynamic invariants. In an evaluation of our JAVALANCHE framework on seven industrial-size programs, we found that mutations that violate invariants are significantly more likely to be detectable by a test suite. As a consequence, mutations with impact on invariants should be focused upon when improving test suites. With less than 3% of equivalent mutants, our approach provides an efficient, precise, and fully automatic measure of the adequacy of a test suite.},
	booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
	pages = {69–80},
	numpages = {12},
	keywords = {mutation testing, dynamic invariants},
	location = {Chicago, IL, USA},
	series = {ISSTA '09}
}

@inproceedings{10.1145/3278186.3278190,
	author = {Vercammen, Sten and Ghafari, Mohammad and Demeyer, Serge and Borg, Markus},
	title = {Goal-Oriented Mutation Testing with Focal Methods},
	year = {2018},
	isbn = {9781450360531},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3278186.3278190},
	doi = {10.1145/3278186.3278190},
	abstract = {Mutation testing is the state-of-the-art technique for assessing the fault-detection capacity of a test suite. Unfortunately, mutation testing consumes enormous computing resources because it runs the whole test suite for each and every injected mutant. In this paper we explore fine-grained traceability links at method level (named focal methods), to reduce the execution time of mutation testing and to verify the quality of the test cases for each individual method, instead of the usually verified overall test suite quality. Validation of our approach on the open source Apache Ant project shows a speed-up of 573.5x for the mutants located in focal methods with a quality score of 80%.},
	booktitle = {Proceedings of the 9th ACM SIGSOFT International Workshop on Automating TEST Case Design, Selection, and Evaluation},
	pages = {23–30},
	numpages = {8},
	keywords = {Mutation testing, Software testing, Focal methods, Feasibility study},
	location = {Lake Buena Vista, FL, USA},
	series = {A-TEST 2018}
}

@phdthesis{lattner2002llvm,
	title={LLVM: An infrastructure for multi-stage optimization},
	author={Lattner, Chris Arthur},
	year={2002},
	school={University of Illinois at Urbana-Champaign}
}

@INPROCEEDINGS{6298092,
	author={T. D. {Hellmann} and A. {Sharma} and J. {Ferreira} and F. {Maurer}},
	booktitle={2012 Agile Conference}, 
	title={Agile Testing: Past, Present, and Future -- Charting a Systematic Map of Testing in Agile Software Development}, 
	year={2012},
	volume={},
	number={},
	pages={55-63},
	doi={10.1109/Agile.2012.8}}

@ARTICLE{6862933,
	author={R. M. {Parizi} and S. P. {Lee} and M. {Dabbagh}},
	journal={IEEE Transactions on Reliability}, 
	title={Achievements and Challenges in State-of-the-Art Software Traceability Between Test and Code Artifacts}, 
	year={2014},
	volume={63},
	number={4},
	pages={913-926},
	doi={10.1109/TR.2014.2338254}}

@INPROCEEDINGS{7335402,
	author={M. {Ghafari} and C. {Ghezzi} and K. {Rubinov}},
	booktitle={2015 IEEE 15th International Working Conference on Source Code Analysis and Manipulation (SCAM)}, 
	title={Automatically identifying focal methods under test in unit test cases}, 
	year={2015},
	volume={},
	number={},
	pages={61-70},
	doi={10.1109/SCAM.2015.7335402}}

@InProceedings{10.1007/978-3-030-24305-0_40,
	author="Csuvik, Viktor
	and Kicsi, Andr{\'a}s
	and Vid{\'a}cs, L{\'a}szl{\'o}",
	editor="Misra, Sanjay
	and Gervasi, Osvaldo
	and Murgante, Beniamino
	and Stankova, Elena
	and Korkhov, Vladimir
	and Torre, Carmelo
	and Rocha, Ana Maria A.C.
	and Taniar, David
	and Apduhan, Bernady O.
	and Tarantino, Eufemia",
	title="Evaluation of Textual Similarity Techniques in Code Level Traceability",
	booktitle="Computational Science and Its Applications -- ICCSA 2019",
	year="2019",
	publisher="Springer International Publishing",
	address="Cham",
	pages="529--543",
	abstract="Automatic recovery of test-to-code traceability links is an important task in many areas of software engineering, like quality assurance and code maintenance. The research community has shown great interest in such a topic and has developed several techniques that already made significant advances in the field. These techniques include text-based learning algorithms, of which corpus is built from the source code of the software components. Several techniques based on information retrieval have been benchmarked, but the capabilities of many learning algorithms have not yet been tested. In this work we examine the textual similarity measures produced by three different machine learning techniques for the recovery of traceability information while also considering various textual representations of the source code. The obtained results are evaluated on 4 open source systems based on naming conventions. We have been able to improve the current textual similarity based state-of-the-art results in the case of each evaluated system.",
	isbn="978-3-030-24305-0"
}

@INPROCEEDINGS{8823709,
	author={V. {Csuvik} and A. {Kicsi} and L. {Vidács}},
	booktitle={2019 IEEE/ACM 10th International Symposium on Software and Systems Traceability (SST)}, 
	title={Source Code Level Word Embeddings in Aiding Semantic Test-to-Code Traceability}, 
	year={2019},
	volume={},
	number={},
	pages={29-36},
	doi={10.1109/SST.2019.00016}}

@INPROCEEDINGS{6080780,
	author={M. {Gethers} and R. {Oliveto} and D. {Poshyvanyk} and A. D. {Lucia}},
	booktitle={2011 27th IEEE International Conference on Software Maintenance (ICSM)}, 
	title={On integrating orthogonal information retrieval methods to improve traceability recovery}, 
	year={2011},
	volume={},
	number={},
	pages={133-142},
	doi={10.1109/ICSM.2011.6080780}}

@INPROCEEDINGS{8452876,
	author={A. {Kicsi} and L. {Tóth} and L. {Vidács}},
	booktitle={2018 IEEE/ACM 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE)}, 
	title={Exploring the Benefits of Utilizing Conceptual Information in Test-to-Code Traceability}, 
	year={2018},
	volume={},
	number={},
	pages={8-14},
	doi={}}

@article{qusef2014recovering,
	title={Recovering test-to-code traceability using slicing and textual analysis},
	author={Qusef, Abdallah and Bavota, Gabriele and Oliveto, Rocco and De Lucia, Andrea and Binkley, Dave},
	journal={Journal of Systems and Software},
	volume={88},
	pages={147--168},
	year={2014},
	publisher={Elsevier}
}

@inproceedings{van2009establishing,
	title={Establishing traceability links between unit test cases and units under test},
	author={Van Rompaey, Bart and Demeyer, Serge},
	booktitle={2009 13th European Conference on Software Maintenance and Reengineering},
	pages={209--218},
	year={2009},
	organization={IEEE}
}

@InProceedings{10.1007/978-3-540-73101-6_14,
	author="Bouillon, Philipp
	and Krinke, Jens
	and Meyer, Nils
	and Steimann, Friedrich",
	editor="Concas, Giulio
	and Damiani, Ernesto
	and Scotto, Marco
	and Succi, Giancarlo",
	title="EzUnit: A Framework for Associating Failed Unit Tests with Potential Programming Errors ",
	booktitle="Agile Processes in Software Engineering and Extreme Programming",
	year="2007",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="101--104",
	abstract="Unit testing is essential in the agile context. A unit test case written long ago may uncover an error introduced only recently, at a time at which awareness of the test and the requirement it expresses may have long vanished. Popular unit testing frameworks such as JUnit may then detect the error at little more cost than the run of a static program checker (compiler). However, unlike such checkers current unit testing frameworks can only detect the presence of errors, they cannot locate them. With EzUnit, we present an extension to the JUnitEclipse plug-in that serves to narrow down error locations, and that marks these locations in the source code in very much the same way syntactic and typing errors are displayed. Because EzUnit is itself designed as a framework, it can be extended by algorithms further narrowing down error locations.",
	isbn="978-3-540-73101-6"
}

@inproceedings{hurdugaci2012aiding,
	title={Aiding software developers to maintain developer tests},
	author={Hurdugaci, Victor and Zaidman, Andy},
	booktitle={2012 16th European Conference on Software Maintenance and Reengineering},
	pages={11--20},
	year={2012},
	organization={IEEE}
}

@inproceedings{white2020establishing,
	title={Establishing Multilevel Test-to-Code Traceability Links},
	author={White, Robert and Krinke, Jens and Tan, Raymond},
	booktitle={42nd International Conference on Software Engineering (ICSE'20)},
	year={2020},
	organization={ACM}
}